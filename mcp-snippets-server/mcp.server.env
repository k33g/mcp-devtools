#MODEL_RUNNER_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1
MODEL_RUNNER_BASE_URL=http://localhost:12434/engines/llama.cpp/v1
EMBEDDING_MODEL=ai/mxbai-embed-large:latest
MCP_HTTP_PORT=9090
LIMIT=0.6
MAX_RESULTS=1
JSON_STORE_FILE_PATH=store/rag-memory-store.json

